\section{Approach}
\label{sec:approach}

\todo{If it has not yet been mentioned that we're throwing a GNN at the AST, put that here}

\subsection{Dataset}

\todo{Talk about TypeScript dataset construction}

\paragraph{Train Test Split}

We made sure to do our train/test split on the dataset not based on the files, but also on the projects, since we are primarily interested in how this approach performs on code that it has never seen before.
Files within the same project do tend to have similar, even identical code snippets, so we wanted to rule out any potential false positives from memorizing such sub-graphs.
However, this does to some extent limit the utility of our predictor within a real world system: a type predictor built into an IDE would have access to other files within the same project that the user has written, and would be able to base predictions on that.
Because of this, we have a separate set of weights for computing the initial node and edge embeddings, so that a model can refine its training on graphs specific to one type of project, while keeping the same node/edge embeddings and predictors, essentially performing a version of the standard NLP-style transfer learning, but for program graphs.

\subsection{Graph Construction}

Because ``graph neural nets'' are such a general framework, the inductive bias for the solution comes primarily from how the input graph is constructed.
Specifically, we must decide on the nodes and edges of our generated graph.
We choose to include the full set of nodes in each program's AST as the nodes in the input graph, using the node's syntactic token type as its embedding.
This allows us to include all potentially relevant structure: we have not only the source level tokens in the source file, but also the abstract structures that those tokens form.

Graph edges are significantly more complicated.
We want to take advantage of all of the important connections that we know about in the program, while also trying to avoid creating as many useless edges as possible, both to help with computation and to induce a stronger prior over the solutions we think might be valid.
Specifically, we take advantage of our knowledge of the important local and nonlocal interactions between various parts of programs, similar to how convolutional networks assume some strong relationship between local pixels~\cite{henaff2015deep}.
There are three specific priors we bake into the edges in our generated graph:

\paragraph{Nodes near a variable in the AST reflect something about that variable's type.}\
\ % need a space after paragraph
\begin{lstlisting}
  let x = y * 2;
\end{lstlisting}
A human trying to infer the type of the variable \texttt{x} in the above code may decide that since the result of multiplying something by a number is almost always a number, \texttt{x} is probably a number.
This corresponds exactly to two types of edges that we include in our generated graph, an \texttt{AstChild} edge from parents to their child nodes in the AST, and an \texttt{AstParent} edge from children to their parent in the AST.

\par\paragraph{Nodes near a variable in the file reflect something about that variable's type.}
\ % need a space after paragraph
\begin{lstlisting}
  let x = 1;
  let y = x;
  ...
  let x = "foo";
\end{lstlisting}
It is clear that both ordering and locality matter in determining the type of \texttt{y}: in the AST, the two statements assigning to \texttt{x} are equidistant and directionally indistinguishable, but the actual \emph{token stream} of file reflects that the first assignment to \texttt{x} precedes the assignment to \texttt{y}, meaning that it may be more likely to affect the type of \texttt{y}, and is also closer, meaning the two statements are more likely to be related.
Because of this, we include two more types of edges in the induced graph, a \texttt{TokenNext} edge from a token to its neighbor in the source file, and a \texttt{TokenPrev} edge which is the reverse.

\paragraph{Nodes that use or define the same variable give information about each other.}
\ % need a space after paragraph
\begin{lstlisting}
  let x = 1;
  ...
  let y = a + (b + (... + x));
\end{lstlisting}
Although the two statements may be arbitrarily nonlocal in both the AST and the source file, they are clearly related, in that \texttt{x}'s type probably influences \texttt{y}'s type.
Because of this, we include one final types of edge, a \texttt{Variable} edge between any of a variable's use and definition.

\paragraph{Example.}
With all of the above nodes and edges included, we generate (a cleaned up version of) the graph shown in Figure~\ref{fig:ast-graph} for the following problem:
\begin{lstlisting}
  let x := 5;
  x = x + 2;
  console.log(x);
\end{lstlisting}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/gen_graph}
  \caption{Generated graph for a simple example}
  \label{fig:ast-graph}
\end{figure}

\paragraph{Probabilistic interpretation}

It can be shown that this particular embedding of the program into the graph, along with the Graph Neural Network algorithm, roughly corresponds to performing approximate posterior inference via loopy belief propagation on a specific Markov Random Field that we believe approximates the true model of the type prediction problem.
A Markov Random Field (MRF) is an undirected graphical model with the Markov assumption, that a node is conditionally independent from all other nodes given its neighbors \todo{cite}.
If we were to construct a Markov Random Field with an unobserved latent variable for each of our AST nodes, adding the various (undirected) edges described above, tag each node with an additional variable (the observed variable representing its AST type), and tag each variable with an additional variable representing its type, we would get a graph that looks roughly like Figure~\ref{fig:mrf-graph}.
We could then perform posterior inference on the type nodes of this graph using Loopy Belief Propagation \todo{cite}, which would give a
\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/mrf_graph}
  \caption{Markov Random Field for an example program. Shaded nodes are observed, highlighted are posteriors}
  \label{fig:mrf-graph}
\end{figure}

We specifically argue the following two points:
\begin{enumerate*}[label=(\roman*)]
\item the induced MRF is the correct model for this problem, and
\item the graph neural network performs posterior inference on this network.
\end{enumerate*}

For point (i), we believe that the three classes of edges (AST edges, source file adjacency edges, and variable use edges) roughly capture the extent of conditional dependence in the model, in that the latent state of a variable (that predicts its type) is roughly conditionally independent from all others given its neighbors along those edges.
This is best argued through locality: the types of variables in a given region of code (e.g. inside of a function) are conditionally independent from the types of variables in a distance region of code (e.g. in a different function) given any variables that are shared or passed between them (the nonlocal \textsc{VariableUse} edges we add).
Some edges we added may be spurious, and while this may make it harder to perform inference (whether in the real MRF or our graph net), the MRF with too many edges can just be viewed as a refinement of the MRF with too few edges.
This is also the case with the undirectedness assumption, where it's likely that some of the edges would ideally be represented as directed edges.
However, this is also the case in using MRFs for images or other applications, and while the assumption can be shown to be at least somewhat incorrect there, MRFs still prove to be useful models~\todo{cite https://www.cise.ufl.edu/~anand/pdf/bookchap.pdf}.

Point (ii) requires arguing that our network architecture roughly performs posterior inference on the network.
This argument is much easier: belief propagation, a message passing algorithm, approximates the correct posterior on graphs with loops~\cite{weiss2000corretness}.
GNNs are in essence a message passing algorithm, where the messages are the result of some function learned by the GNN on the current latent state of a given node.
By merit of being neural networks, GNNs are capable of approximating any function~\cite{hornik1989multilayer} (and storing latent state), meaning that GNNs are capable of learning belief propagation (assuming we run the message passing for enough iterations).
Therefore, assuming that training our GNN finds its global optimum, we are guaranteed a solution at least as good as the approximate solution of belief propagation on the MRF, meaning that a GNN should be capable of solving the type inference problem.

\subsection{Embeddings}

\todo{fill out this section}

\subsection{Architecture}

We implemented our graph neural nets using DeepMind's Graph Nets framework~\cite{deepmind2018graph}.

\subsection{Implementation}

We implemented our type prediction algorithm using using DeepMind's Graph Nets framework~\cite{deepmind2018graph}, along with a significant amount of custom TensorFlow~\cite{google2015tensorflow} to collect metrics and perform experiments.


%%% Local Variables:
%%% TeX-master: "main"
%%% End: