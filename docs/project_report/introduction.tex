\section{Introduction}
\label{sec:introduction}
Inferring properties of computer programs is a task central to the programming languages (PL) community.
Although many challenges in the field are undecidable, like figuring out whether a program terminates or finding a test case which crashes a program, the program analysis community has designed algorithms and techniques that approximate solutions to such undecidable problems.
These techniques have been explored to an extent that working solutions have been shipped in real-time, commercial products.

One such property of interest is ascertaining the types of variables used in programs.
Static, strongly-typed languages provide considerable guarantees at compile time, enabling programmers to write more correct and interpretable code.
Although the advantages of this paradigm are well understood by the programming community, many popular languages such as Python, Ruby, and Javascript still do not enforce static typing.
These languages prevent typing errors at run time, and do minimal (if any) checking at compile time.
This approach of dynamic typing is referred to as \textit{duck typing} (``If it walks like a duck and it quacks like a duck, then it must be a duck'').
Despite the lack of static assurances given by duck typing, it is widely adopted and is used extensively in production systems.
This calls for some ability to infer, at compile time, the type of variables and expressions in the program, to statically rule out bugs while still enjoying the usability benefits of duck typing.

One recent approach to this inference problem is \emph{gradual typing}~\cite{siek2006gradual}, which allows for partial specification of type annotations in an otherwise untyped language.
This enables established type-inference algorithms to determine types of other variables used in a program, even ones that do not have explicit annotations.
Another approach, which is the subject of this work, is to infer types statistically.
The problem of inferring types can be cast as a supervised learning problem, where a model can be trained on a corpus of programs with identified types in order to be able to infer types of unseen variables in unseen programs.

This statistical approach has been validated with a modest degree of success in previous work~\cite{hellendoorn2018deep}.
Allamanis \textit{et al.} modeled the problem as a sequence translation task, and trained bi-directional RNNs to predict types (see Section~\ref{sec:approach}).
In this work, we ask whether there are inductive biases which are unique to this input space, computer programs, and how they can be exploited in such a prediction task.
We motivate this problem as an inference task over a probabilistic graphical model, and approximate it using a graph-based neural network.
We show that this modeling assumption outperforms sequence-based approaches for type inference.