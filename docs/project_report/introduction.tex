\section{Introduction}
\label{sec:introduction}
Inferring properties of computer programs is a task central to the programming languages (PL) community. Although important questions like whether a program shall terminate, or finding a test case which shall crash a program are undecidable, the program analysis community, over the last few decades, has designed algorithms and techniques which solve such undecidable problems to a good approximation, and to an extent where such solutions have been shipped to real-time, commercial products.

One such property of interest is ascertaining types of variables used in programs. Static, strongly-typed languages provide considerable guarantees at compile-time, enabling programmers to write bug-free, well understandable code. Although the advantages of this paradigm have been well understood by the programming community, there exist many popular languages such as Python, Ruby, and Javascript which do not enforce static typing. These languages prevent typing errors at run-time, and do little type-checking at compile-time. This approach of exclusive dynamic typing is referred to as \textit{duck-typing}. Despite the various pros and cons of duck-typing, it is widely adopted and is used extensively in production systems. This warrants some form of retrospective ability which can provide, at compile time, type-information with an acceptable degree of accuracy.

One approach to having such retrospective type-checking on a language which does not inherently support static type checking is having programmers provide partial information on types of variables used in their programs. This enables established type-inference algorithms to determine types of various variables used in a program, and is bound by the amount of annotation which a user provides. Another approach, which is the subject of this work, is to infer types statistically. The problem of inferring types can be cast as one in supervised machine learning, wherein from a given corpus of programs with identified types, supervised models can infer types of unseen variables, in unseen programs.

This broader approach has been validated with a modest degree of success in previous work \cite{hellendoorn2018deep}. Allamanis \textit{et al.} modeled the problem as a sequence translation task, and trained bi-directional RNNs to predict types (see Section \ref{sec:approach}). In this work, we ask whether there are inductive biases which are unique to the input space - computer programs, and whether they can be exploited in such a prediction task. We motivate this problem as an inference task over a probabilistic graphical model, and approximate it using a graph-based neural networks. We show that such a modeling approach does better than modeling it as a sequence prediction task.


%%% Local Variables:
%%% TeX-master: "main"
%%% End: